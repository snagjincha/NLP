{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 8565,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03502626970227671,
      "grad_norm": 4.735169887542725,
      "learning_rate": 4.942206654991244e-05,
      "loss": 7.8381,
      "step": 100
    },
    {
      "epoch": 0.07005253940455342,
      "grad_norm": 5.145692825317383,
      "learning_rate": 4.8838295388207827e-05,
      "loss": 8.182,
      "step": 200
    },
    {
      "epoch": 0.10507880910683012,
      "grad_norm": 4.654270172119141,
      "learning_rate": 4.825452422650321e-05,
      "loss": 8.317,
      "step": 300
    },
    {
      "epoch": 0.14010507880910683,
      "grad_norm": 4.187089920043945,
      "learning_rate": 4.76707530647986e-05,
      "loss": 8.546,
      "step": 400
    },
    {
      "epoch": 0.17513134851138354,
      "grad_norm": 7.534560203552246,
      "learning_rate": 4.708698190309399e-05,
      "loss": 8.6253,
      "step": 500
    },
    {
      "epoch": 0.21015761821366025,
      "grad_norm": 7.092065334320068,
      "learning_rate": 4.650321074138938e-05,
      "loss": 8.6948,
      "step": 600
    },
    {
      "epoch": 0.24518388791593695,
      "grad_norm": 7.087944984436035,
      "learning_rate": 4.5919439579684764e-05,
      "loss": 8.6976,
      "step": 700
    },
    {
      "epoch": 0.28021015761821366,
      "grad_norm": 7.6973772048950195,
      "learning_rate": 4.533566841798015e-05,
      "loss": 8.7968,
      "step": 800
    },
    {
      "epoch": 0.31523642732049034,
      "grad_norm": 6.080440521240234,
      "learning_rate": 4.4751897256275543e-05,
      "loss": 8.779,
      "step": 900
    },
    {
      "epoch": 0.3502626970227671,
      "grad_norm": 6.512143611907959,
      "learning_rate": 4.416812609457093e-05,
      "loss": 8.751,
      "step": 1000
    },
    {
      "epoch": 0.38528896672504376,
      "grad_norm": 8.202852249145508,
      "learning_rate": 4.3584354932866316e-05,
      "loss": 8.8605,
      "step": 1100
    },
    {
      "epoch": 0.4203152364273205,
      "grad_norm": 5.7514777183532715,
      "learning_rate": 4.300058377116171e-05,
      "loss": 8.906,
      "step": 1200
    },
    {
      "epoch": 0.4553415061295972,
      "grad_norm": 7.086915969848633,
      "learning_rate": 4.2416812609457095e-05,
      "loss": 8.8876,
      "step": 1300
    },
    {
      "epoch": 0.4903677758318739,
      "grad_norm": 5.255412578582764,
      "learning_rate": 4.183304144775249e-05,
      "loss": 8.883,
      "step": 1400
    },
    {
      "epoch": 0.5253940455341506,
      "grad_norm": 6.6712565422058105,
      "learning_rate": 4.124927028604787e-05,
      "loss": 8.7787,
      "step": 1500
    },
    {
      "epoch": 0.5604203152364273,
      "grad_norm": 6.443661212921143,
      "learning_rate": 4.066549912434326e-05,
      "loss": 8.9157,
      "step": 1600
    },
    {
      "epoch": 0.5954465849387041,
      "grad_norm": 5.385892391204834,
      "learning_rate": 4.008172796263865e-05,
      "loss": 8.8295,
      "step": 1700
    },
    {
      "epoch": 0.6304728546409807,
      "grad_norm": 5.348865985870361,
      "learning_rate": 3.949795680093404e-05,
      "loss": 8.7855,
      "step": 1800
    },
    {
      "epoch": 0.6654991243432574,
      "grad_norm": 6.167888164520264,
      "learning_rate": 3.891418563922942e-05,
      "loss": 8.7781,
      "step": 1900
    },
    {
      "epoch": 0.7005253940455342,
      "grad_norm": 6.230989933013916,
      "learning_rate": 3.833041447752481e-05,
      "loss": 8.8057,
      "step": 2000
    },
    {
      "epoch": 0.7355516637478109,
      "grad_norm": 8.609590530395508,
      "learning_rate": 3.77466433158202e-05,
      "loss": 8.7222,
      "step": 2100
    },
    {
      "epoch": 0.7705779334500875,
      "grad_norm": 5.309542179107666,
      "learning_rate": 3.716287215411559e-05,
      "loss": 8.7361,
      "step": 2200
    },
    {
      "epoch": 0.8056042031523643,
      "grad_norm": 6.9105424880981445,
      "learning_rate": 3.657910099241098e-05,
      "loss": 8.799,
      "step": 2300
    },
    {
      "epoch": 0.840630472854641,
      "grad_norm": 6.758456230163574,
      "learning_rate": 3.5995329830706364e-05,
      "loss": 8.7659,
      "step": 2400
    },
    {
      "epoch": 0.8756567425569177,
      "grad_norm": 5.3403167724609375,
      "learning_rate": 3.5411558669001757e-05,
      "loss": 8.7797,
      "step": 2500
    },
    {
      "epoch": 0.9106830122591943,
      "grad_norm": 5.292734146118164,
      "learning_rate": 3.482778750729714e-05,
      "loss": 8.7798,
      "step": 2600
    },
    {
      "epoch": 0.9457092819614711,
      "grad_norm": 5.853211402893066,
      "learning_rate": 3.424401634559253e-05,
      "loss": 8.6754,
      "step": 2700
    },
    {
      "epoch": 0.9807355516637478,
      "grad_norm": 5.555971622467041,
      "learning_rate": 3.3660245183887915e-05,
      "loss": 8.6914,
      "step": 2800
    },
    {
      "epoch": 1.0157618213660244,
      "grad_norm": 5.313249588012695,
      "learning_rate": 3.307647402218331e-05,
      "loss": 8.7185,
      "step": 2900
    },
    {
      "epoch": 1.0507880910683012,
      "grad_norm": 4.7802414894104,
      "learning_rate": 3.2492702860478694e-05,
      "loss": 8.6724,
      "step": 3000
    },
    {
      "epoch": 1.085814360770578,
      "grad_norm": 9.794299125671387,
      "learning_rate": 3.190893169877408e-05,
      "loss": 8.6282,
      "step": 3100
    },
    {
      "epoch": 1.1208406304728546,
      "grad_norm": 6.651682376861572,
      "learning_rate": 3.132516053706947e-05,
      "loss": 8.6856,
      "step": 3200
    },
    {
      "epoch": 1.1558669001751314,
      "grad_norm": 7.207196235656738,
      "learning_rate": 3.074138937536486e-05,
      "loss": 8.6482,
      "step": 3300
    },
    {
      "epoch": 1.1908931698774081,
      "grad_norm": 6.9217658042907715,
      "learning_rate": 3.015761821366025e-05,
      "loss": 8.6076,
      "step": 3400
    },
    {
      "epoch": 1.2259194395796849,
      "grad_norm": 5.62957763671875,
      "learning_rate": 2.9573847051955632e-05,
      "loss": 8.5131,
      "step": 3500
    },
    {
      "epoch": 1.2609457092819616,
      "grad_norm": 7.912027835845947,
      "learning_rate": 2.899007589025102e-05,
      "loss": 8.5934,
      "step": 3600
    },
    {
      "epoch": 1.295971978984238,
      "grad_norm": 6.227609634399414,
      "learning_rate": 2.840630472854641e-05,
      "loss": 8.5002,
      "step": 3700
    },
    {
      "epoch": 1.3309982486865148,
      "grad_norm": 6.727534770965576,
      "learning_rate": 2.78225335668418e-05,
      "loss": 8.5371,
      "step": 3800
    },
    {
      "epoch": 1.3660245183887916,
      "grad_norm": 6.928287982940674,
      "learning_rate": 2.7238762405137187e-05,
      "loss": 8.5946,
      "step": 3900
    },
    {
      "epoch": 1.4010507880910683,
      "grad_norm": 7.206127643585205,
      "learning_rate": 2.6654991243432577e-05,
      "loss": 8.6099,
      "step": 4000
    },
    {
      "epoch": 1.436077057793345,
      "grad_norm": 7.838876724243164,
      "learning_rate": 2.6071220081727966e-05,
      "loss": 8.6275,
      "step": 4100
    },
    {
      "epoch": 1.4711033274956218,
      "grad_norm": 8.178716659545898,
      "learning_rate": 2.5487448920023356e-05,
      "loss": 8.5961,
      "step": 4200
    },
    {
      "epoch": 1.5061295971978983,
      "grad_norm": 6.231659412384033,
      "learning_rate": 2.4903677758318742e-05,
      "loss": 8.4511,
      "step": 4300
    },
    {
      "epoch": 1.541155866900175,
      "grad_norm": 6.86810827255249,
      "learning_rate": 2.4319906596614128e-05,
      "loss": 8.529,
      "step": 4400
    },
    {
      "epoch": 1.5761821366024518,
      "grad_norm": 7.9243645668029785,
      "learning_rate": 2.3736135434909518e-05,
      "loss": 8.5019,
      "step": 4500
    },
    {
      "epoch": 1.6112084063047285,
      "grad_norm": 7.151944637298584,
      "learning_rate": 2.3152364273204904e-05,
      "loss": 8.4673,
      "step": 4600
    },
    {
      "epoch": 1.6462346760070052,
      "grad_norm": 6.0216779708862305,
      "learning_rate": 2.2568593111500294e-05,
      "loss": 8.4975,
      "step": 4700
    },
    {
      "epoch": 1.681260945709282,
      "grad_norm": 7.175456523895264,
      "learning_rate": 2.198482194979568e-05,
      "loss": 8.6187,
      "step": 4800
    },
    {
      "epoch": 1.7162872154115587,
      "grad_norm": 8.133942604064941,
      "learning_rate": 2.140105078809107e-05,
      "loss": 8.4993,
      "step": 4900
    },
    {
      "epoch": 1.7513134851138354,
      "grad_norm": 6.970055103302002,
      "learning_rate": 2.081727962638646e-05,
      "loss": 8.4409,
      "step": 5000
    },
    {
      "epoch": 1.7863397548161122,
      "grad_norm": 8.996270179748535,
      "learning_rate": 2.0233508464681845e-05,
      "loss": 8.5293,
      "step": 5100
    },
    {
      "epoch": 1.821366024518389,
      "grad_norm": 6.449883460998535,
      "learning_rate": 1.9649737302977235e-05,
      "loss": 8.5554,
      "step": 5200
    },
    {
      "epoch": 1.8563922942206657,
      "grad_norm": 7.292844295501709,
      "learning_rate": 1.9065966141272624e-05,
      "loss": 8.5057,
      "step": 5300
    },
    {
      "epoch": 1.8914185639229422,
      "grad_norm": 6.985714435577393,
      "learning_rate": 1.848219497956801e-05,
      "loss": 8.5396,
      "step": 5400
    },
    {
      "epoch": 1.926444833625219,
      "grad_norm": 6.123523235321045,
      "learning_rate": 1.78984238178634e-05,
      "loss": 8.5278,
      "step": 5500
    },
    {
      "epoch": 1.9614711033274956,
      "grad_norm": 6.4985127449035645,
      "learning_rate": 1.7314652656158786e-05,
      "loss": 8.541,
      "step": 5600
    },
    {
      "epoch": 1.9964973730297724,
      "grad_norm": 6.593043327331543,
      "learning_rate": 1.6730881494454176e-05,
      "loss": 8.4338,
      "step": 5700
    },
    {
      "epoch": 2.031523642732049,
      "grad_norm": 8.715559959411621,
      "learning_rate": 1.6147110332749562e-05,
      "loss": 8.5329,
      "step": 5800
    },
    {
      "epoch": 2.0665499124343256,
      "grad_norm": 5.82045316696167,
      "learning_rate": 1.556333917104495e-05,
      "loss": 8.5701,
      "step": 5900
    },
    {
      "epoch": 2.1015761821366024,
      "grad_norm": 6.494964122772217,
      "learning_rate": 1.497956800934034e-05,
      "loss": 8.4309,
      "step": 6000
    },
    {
      "epoch": 2.136602451838879,
      "grad_norm": 6.6685309410095215,
      "learning_rate": 1.4395796847635729e-05,
      "loss": 8.4493,
      "step": 6100
    },
    {
      "epoch": 2.171628721541156,
      "grad_norm": 8.963759422302246,
      "learning_rate": 1.3812025685931115e-05,
      "loss": 8.4975,
      "step": 6200
    },
    {
      "epoch": 2.2066549912434326,
      "grad_norm": 6.388703346252441,
      "learning_rate": 1.3228254524226505e-05,
      "loss": 8.3475,
      "step": 6300
    },
    {
      "epoch": 2.2416812609457093,
      "grad_norm": 12.914636611938477,
      "learning_rate": 1.2644483362521891e-05,
      "loss": 8.4159,
      "step": 6400
    },
    {
      "epoch": 2.276707530647986,
      "grad_norm": 7.626158237457275,
      "learning_rate": 1.206071220081728e-05,
      "loss": 8.5037,
      "step": 6500
    },
    {
      "epoch": 2.3117338003502628,
      "grad_norm": 6.663082599639893,
      "learning_rate": 1.1476941039112669e-05,
      "loss": 8.4749,
      "step": 6600
    },
    {
      "epoch": 2.3467600700525395,
      "grad_norm": 6.318232536315918,
      "learning_rate": 1.0893169877408056e-05,
      "loss": 8.339,
      "step": 6700
    },
    {
      "epoch": 2.3817863397548162,
      "grad_norm": 7.395711898803711,
      "learning_rate": 1.0309398715703444e-05,
      "loss": 8.4493,
      "step": 6800
    },
    {
      "epoch": 2.416812609457093,
      "grad_norm": 5.465665340423584,
      "learning_rate": 9.725627553998832e-06,
      "loss": 8.4242,
      "step": 6900
    },
    {
      "epoch": 2.4518388791593697,
      "grad_norm": 9.000205993652344,
      "learning_rate": 9.14185639229422e-06,
      "loss": 8.401,
      "step": 7000
    },
    {
      "epoch": 2.4868651488616464,
      "grad_norm": 7.3774189949035645,
      "learning_rate": 8.55808523058961e-06,
      "loss": 8.4539,
      "step": 7100
    },
    {
      "epoch": 2.521891418563923,
      "grad_norm": 8.734063148498535,
      "learning_rate": 7.974314068884998e-06,
      "loss": 8.4446,
      "step": 7200
    },
    {
      "epoch": 2.5569176882662,
      "grad_norm": 6.202893257141113,
      "learning_rate": 7.3905429071803855e-06,
      "loss": 8.3948,
      "step": 7300
    },
    {
      "epoch": 2.591943957968476,
      "grad_norm": 7.502036094665527,
      "learning_rate": 6.806771745475773e-06,
      "loss": 8.4926,
      "step": 7400
    },
    {
      "epoch": 2.626970227670753,
      "grad_norm": 7.5254034996032715,
      "learning_rate": 6.223000583771162e-06,
      "loss": 8.3494,
      "step": 7500
    },
    {
      "epoch": 2.6619964973730297,
      "grad_norm": 9.114995002746582,
      "learning_rate": 5.639229422066551e-06,
      "loss": 8.4341,
      "step": 7600
    },
    {
      "epoch": 2.6970227670753064,
      "grad_norm": 6.253907203674316,
      "learning_rate": 5.055458260361939e-06,
      "loss": 8.3707,
      "step": 7700
    },
    {
      "epoch": 2.732049036777583,
      "grad_norm": 6.8464250564575195,
      "learning_rate": 4.471687098657327e-06,
      "loss": 8.4519,
      "step": 7800
    },
    {
      "epoch": 2.76707530647986,
      "grad_norm": 7.0570855140686035,
      "learning_rate": 3.887915936952715e-06,
      "loss": 8.2733,
      "step": 7900
    },
    {
      "epoch": 2.8021015761821366,
      "grad_norm": 7.650781631469727,
      "learning_rate": 3.3041447752481033e-06,
      "loss": 8.45,
      "step": 8000
    },
    {
      "epoch": 2.8371278458844134,
      "grad_norm": 8.255894660949707,
      "learning_rate": 2.720373613543491e-06,
      "loss": 8.4157,
      "step": 8100
    },
    {
      "epoch": 2.87215411558669,
      "grad_norm": 5.640872955322266,
      "learning_rate": 2.136602451838879e-06,
      "loss": 8.4964,
      "step": 8200
    },
    {
      "epoch": 2.907180385288967,
      "grad_norm": 6.506328582763672,
      "learning_rate": 1.5528312901342674e-06,
      "loss": 8.365,
      "step": 8300
    },
    {
      "epoch": 2.9422066549912436,
      "grad_norm": 6.278731822967529,
      "learning_rate": 9.690601284296555e-07,
      "loss": 8.4362,
      "step": 8400
    },
    {
      "epoch": 2.9772329246935203,
      "grad_norm": 7.148090839385986,
      "learning_rate": 3.8528896672504383e-07,
      "loss": 8.4505,
      "step": 8500
    }
  ],
  "logging_steps": 100,
  "max_steps": 8565,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 342021709135872.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
