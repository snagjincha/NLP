{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b0d591ca-7145-4b7c-bab0-d1e015a8ea37",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"[NLP] Position Embedding vs Position Encoding\"\n",
    "author: \"차상진\"\n",
    "date: \"2025-03-20\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1de1cb-124d-447f-a35f-6593e0fd3fa9",
   "metadata": {},
   "source": [
    "# 1. 위치 임베딩 vs 위치 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cf9e81-7427-4325-96a5-8752c4675d69",
   "metadata": {},
   "source": [
    "`-` 위치 임베딩\n",
    "\n",
    "위치별로 학습 가능한 임베딩을 부여하는 방식 (단어들의 위치에 따라 **학습 가능한** 값을 부여)\n",
    "\n",
    "- 모델이 학습을 통해 위치별 임베딩 값을 조정할 수 있다.\n",
    "- 예를 들어, 위치 0번, 1번, 2번, ...에 대해 각각 학습 가능한 벡터가 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1960a7d-0e73-40f3-a8fe-27fc586a8e3a",
   "metadata": {},
   "source": [
    "$PE_{learned}(pos)=Embedding(pos)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79b7a96-8057-471a-b93c-a5f23a1f7fd8",
   "metadata": {},
   "source": [
    "`-` 위치 인코딩 \n",
    "\n",
    "위치 정보를 사인(sin)과 코사인(cos) 함수로 생성하는 방식이야. (단어들의 위치에 따라 **학습 불가능한** 상수 값을 부여\n",
    "\n",
    "- 사전 정의된 함수(수학적 패턴)를 사용하기 때문에 변화하지 않는 상수 값\n",
    "- 학습을 통해 조정되지 않고, 입력 데이터에 대해 고정된 값을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d05ec7-78ee-454e-926c-2e3bcbe2f7de",
   "metadata": {},
   "source": [
    "$PE(pos, 2i) = \\sin\\left(\\frac{pos}{10000^{\\frac{2i}{d}}}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23929953-beca-4de3-8105-d230db2ae052",
   "metadata": {},
   "source": [
    "$PE(pos, 2i+1) = \\cos\\left(\\frac{pos}{10000^{\\frac{2i}{d}}}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc48060-1363-4073-8ab2-7b4edca20a34",
   "metadata": {},
   "source": [
    "- pos는 단어의 위치,\n",
    "- i는 임베딩 차원의 인덱스\n",
    "- d는 임베딩 차원 크기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a79a8b-7708-4a42-bc4c-91a680bb515c",
   "metadata": {},
   "source": [
    "# 2. 각 방식의 장단점"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246d217d-c7b1-4723-b80c-fdc1e075569a",
   "metadata": {},
   "source": [
    "`Good` 위치 임베딩 장점\n",
    "1. 학습 가능: 위치 임베딩은 학습이 가능하기에 모델이 데이터에 맞춰 위치 정보를 **최적화**할 수 있다.\n",
    "2. 더 높은 유연성: 모델이 데이터를 통해 학습하므로, 특정 문맥이나 도메인에 맞춰 위치 표현을 다르게 할 수 있다.\n",
    "\n",
    "`Bad` 위치 임베딩 단점\n",
    "1. 메모리와 연산 비용: 위치 임베딩은 각 위치마다 임베딩 벡터를 학습해야 하기 때문에, 추가적인 파라미터와 메모리를 사용한다.\n",
    "2. 오버피팅: 학습 가능한 위치 벡터가 많아지면, 모델이 훈련 데이터에 **과적합**할 가능성이 커질 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b39a8d4-df26-4749-ad1d-f0974ac20d6d",
   "metadata": {},
   "source": [
    "`Good` 위치 인코딩 장점\n",
    "1. 메모리 효율성: 파라미터가 없기에 메모리 부담이 적다.\n",
    "2. 고정된 패턴: 위치 인코딩은 고정된 수학적 패턴을 사용하므로, 특정 위치 간의 관계를 명확하게 정의할 수 있다.\n",
    "\n",
    "`Bad` 위치 인코딩 단점\n",
    "1. 학습할 수 없음: 모델이 학습을 통해 위치 정보를 더 정교하게 조정할 수 없다.\n",
    "2. 유연성 부족: 모든 문장에서 같은 패턴을 사용하기에 특정 도메인이나 데이터 셋에 대해 최적화된 위치 정보를 표현할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add4e35b-04a8-4f06-8040-6628af53a16e",
   "metadata": {},
   "source": [
    "# 3. 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc31736-0c9d-411e-a2c9-39afc41419d4",
   "metadata": {},
   "source": [
    "- 위치 인코딩은 일반적인 용도와 효율성이 중요한 경우에 적합하다.\n",
    "- 위치 임베딩은 특정 도메인이나 고유한 데이터셋에 대해 더 정교한 위치 표현이 필요한 경우에 유리하다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
